{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ4M8Znd4_ep"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "import time\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pickle\n",
        "import os\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkpfPDS1Z8a8",
        "outputId": "3219bc62-f97b-499f-a28a-0379e1560f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vYZA1zq4_e7"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Sentence entailment/train_data.csv')[:100000]\n",
        "val_df   = pd.read_csv('/content/drive/My Drive/Sentence entailment/val_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NgPYXBg4_e7"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.dropna()\n",
        "val_df = val_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMTQb1iMF54W"
      },
      "outputs": [],
      "source": [
        "train_df['sentence1'] = train_df['sentence1'].astype(str)\n",
        "train_df['sentence2'] = train_df['sentence2'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMzPNmtpF8yg"
      },
      "outputs": [],
      "source": [
        "val_df['sentence1'] = val_df['sentence1'].astype(str)\n",
        "val_df['sentence2'] = val_df['sentence2'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diS3wCm14_e9"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
        "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "WinUrXE04_e9",
        "outputId": "974ce2c2-04b4-40e2-f33d-ee172eb6c49e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Conceptually cream skimming has two basic dime...</td>\n",
              "      <td>Product and geography are what make cream skim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>you know during the season and i guess at at y...</td>\n",
              "      <td>You lose the things to the following level if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>One of our number will carry out your instruct...</td>\n",
              "      <td>A member of my team will execute your orders w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>How do you know? All this is their information...</td>\n",
              "      <td>This information belongs to them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>yeah i tell you what though if you go price so...</td>\n",
              "      <td>The tennis shoes have a range of prices.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>99995</td>\n",
              "      <td>neutral</td>\n",
              "      <td>She'd probably ask you the way to the Moat Hou...</td>\n",
              "      <td>Tuppence went missing whilst looking for the m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>99996</td>\n",
              "      <td>entailment</td>\n",
              "      <td>When reporters asked whether Clinton should re...</td>\n",
              "      <td>Personal destruction politics should not decid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>99997</td>\n",
              "      <td>neutral</td>\n",
              "      <td>For the hikers, a bus goes to a point quite cl...</td>\n",
              "      <td>At the summit, the view is said to be the best...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>99998</td>\n",
              "      <td>entailment</td>\n",
              "      <td>The capital of the Gododdin was Din Eidyn (the...</td>\n",
              "      <td>Edinburgh derived its name from Din Eidyn, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>99999</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>In any event, Gore dropped out of the race sho...</td>\n",
              "      <td>In each one of the events, Bush quit the race ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99985 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                          sentence2\n",
              "0               0  ...  Product and geography are what make cream skim...\n",
              "1               1  ...  You lose the things to the following level if ...\n",
              "2               2  ...  A member of my team will execute your orders w...\n",
              "3               3  ...                  This information belongs to them.\n",
              "4               4  ...           The tennis shoes have a range of prices.\n",
              "...           ...  ...                                                ...\n",
              "99995       99995  ...  Tuppence went missing whilst looking for the m...\n",
              "99996       99996  ...  Personal destruction politics should not decid...\n",
              "99997       99997  ...  At the summit, the view is said to be the best...\n",
              "99998       99998  ...  Edinburgh derived its name from Din Eidyn, the...\n",
              "99999       99999  ...  In each one of the events, Bush quit the race ...\n",
              "\n",
              "[99985 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6e4dxTks4_e-",
        "outputId": "d6e58040-d442-48e3-9f44-563dca5b9031"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>The new rights are nice enough</td>\n",
              "      <td>Everyone really likes the newest benefits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>This site includes a list of all award winners...</td>\n",
              "      <td>The Government Executive articles housed on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>uh i don't know i i have mixed emotions about ...</td>\n",
              "      <td>I like him for the most part, but would still ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>yeah i i think my favorite restaurant is alway...</td>\n",
              "      <td>My favorite restaurants are always at least a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>i don't know um do you do a lot of camping</td>\n",
              "      <td>I know exactly.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>9995</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Since 1998, LSC has initiated and overseen sig...</td>\n",
              "      <td>LSC has been focusing on improving it's state ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>9996</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Eighty percent of pagers in the United States ...</td>\n",
              "      <td>Pagers in the United States were unaffected by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>9997</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Finally, the FDA will conduct workshops, issue...</td>\n",
              "      <td>The FDA is set to conduct workshops.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>9998</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Cirque du Soleil's The latest from the acclaim...</td>\n",
              "      <td>Cirque du Soleil is an international troupe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>9999</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>i'll listen  and agree with what i think sound...</td>\n",
              "      <td>I wont even bother listening.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                          sentence2\n",
              "0              0  ...         Everyone really likes the newest benefits \n",
              "1              1  ...  The Government Executive articles housed on th...\n",
              "2              2  ...  I like him for the most part, but would still ...\n",
              "3              3  ...  My favorite restaurants are always at least a ...\n",
              "4              4  ...                                    I know exactly.\n",
              "...          ...  ...                                                ...\n",
              "9810        9995  ...  LSC has been focusing on improving it's state ...\n",
              "9811        9996  ...  Pagers in the United States were unaffected by...\n",
              "9812        9997  ...              The FDA is set to conduct workshops. \n",
              "9813        9998  ...       Cirque du Soleil is an international troupe.\n",
              "9814        9999  ...                      I wont even bother listening.\n",
              "\n",
              "[9815 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk96lNh94_e_"
      },
      "outputs": [],
      "source": [
        "class MNLIDataBert(Dataset):\n",
        "\n",
        "  def __init__(self, train_df, val_df):\n",
        "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "\n",
        "    self.base_path = '/content/'\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    self.train_data = None\n",
        "    self.val_data = None\n",
        "    self.init_data()\n",
        "\n",
        "  def init_data(self):\n",
        "    # Saving takes too much RAM\n",
        "    #\n",
        "    # if os.path.exists(os.path.join(self.base_path, 'train_data.pkl')):\n",
        "    #   print(\"Found training data\")\n",
        "    #   with open(os.path.join(self.base_path, 'train_data.pkl'), 'rb') as f:\n",
        "    #     self.train_data = pickle.load(f)\n",
        "    # else:\n",
        "    #   self.train_data = self.load_data(self.train_df)\n",
        "    #   with open(os.path.join(self.base_path, 'train_data.pkl'), 'wb') as f:\n",
        "    #     pickle.dump(self.train_data, f)\n",
        "    # if os.path.exists(os.path.join(self.base_path, 'val_data.pkl')):\n",
        "    #   print(\"Found val data\")\n",
        "    #   with open(os.path.join(self.base_path, 'val_data.pkl'), 'rb') as f:\n",
        "    #     self.val_data = pickle.load(f)\n",
        "    # else:\n",
        "    #   self.val_data = self.load_data(self.val_df)\n",
        "    #   with open(os.path.join(self.base_path, 'val_data.pkl'), 'wb') as f:\n",
        "    #     pickle.dump(self.val_data, f)\n",
        "    self.train_data = self.load_data(self.train_df)\n",
        "    self.val_data = self.load_data(self.val_df)\n",
        "\n",
        "  def load_data(self, df):\n",
        "    MAX_LEN = 512\n",
        "    token_ids = []\n",
        "    mask_ids = []\n",
        "    seg_ids = []\n",
        "    y = []\n",
        "\n",
        "    premise_list = df['sentence1'].to_list()\n",
        "    hypothesis_list = df['sentence2'].to_list()\n",
        "    label_list = df['gold_label'].to_list()\n",
        "\n",
        "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
        "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
        "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
        "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
        "      premise_len = len(premise_id)\n",
        "      hypothesis_len = len(hypothesis_id)\n",
        "\n",
        "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
        "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
        "\n",
        "      token_ids.append(torch.tensor(pair_token_ids))\n",
        "      seg_ids.append(segment_ids)\n",
        "      mask_ids.append(attention_mask_ids)\n",
        "      y.append(self.label_dict[label])\n",
        "    \n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
        "    y = torch.tensor(y)\n",
        "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
        "    print(len(dataset))\n",
        "    return dataset\n",
        "\n",
        "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
        "    train_loader = DataLoader(\n",
        "      self.train_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "      self.val_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md52P1z14_e_",
        "outputId": "3421aec1-128f-4589-874d-a82372138365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99985\n",
            "9815\n"
          ]
        }
      ],
      "source": [
        "mnli_dataset = MNLIDataBert(train_df, val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LSyABLG4_fA"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader = mnli_dataset.get_data_loaders(batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdc4Cs2DEjt",
        "outputId": "98759f4f-ead1-4b1d-c20c-0ce4996de3ed"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxzpENXlEh-u"
      },
      "outputs": [],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is1TqwTREid9"
      },
      "outputs": [],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79aI1dun4_fB",
        "outputId": "c2f15bac-22d1-403b-cc1b-0a758cae0433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 109,484,547 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhU855Cw4_fB"
      },
      "outputs": [],
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfhYO7Db4_fB"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer):  \n",
        "  total_step = len(train_loader)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_acc  = 0\n",
        "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      pair_token_ids = pair_token_ids.to(device)\n",
        "      mask_ids = mask_ids.to(device)\n",
        "      seg_ids = seg_ids.to(device)\n",
        "      labels = y.to(device)\n",
        "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
        "      loss, prediction = model(pair_token_ids, \n",
        "                             token_type_ids=seg_ids, \n",
        "                             attention_mask=mask_ids, \n",
        "                             labels=labels).values()\n",
        "\n",
        "      # loss = criterion(prediction, labels)\n",
        "      acc = multi_acc(prediction, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      total_train_loss += loss.item()\n",
        "      total_train_acc  += acc.item()\n",
        "\n",
        "    train_acc  = total_train_acc/len(train_loader)\n",
        "    train_loss = total_train_loss/len(train_loader)\n",
        "    model.eval()\n",
        "    total_val_acc  = 0\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        pair_token_ids = pair_token_ids.to(device)\n",
        "        mask_ids = mask_ids.to(device)\n",
        "        seg_ids = seg_ids.to(device)\n",
        "        labels = y.to(device)\n",
        "\n",
        "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
        "        loss, prediction = model(pair_token_ids, \n",
        "                             token_type_ids=seg_ids, \n",
        "                             attention_mask=mask_ids, \n",
        "                             labels=labels).values()\n",
        "        \n",
        "        # loss = criterion(prediction, labels)\n",
        "        acc = multi_acc(prediction, labels)\n",
        "\n",
        "        total_val_loss += loss.item()\n",
        "        total_val_acc  += acc.item()\n",
        "\n",
        "    val_acc  = total_val_acc/len(val_loader)\n",
        "    val_loss = total_val_loss/len(val_loader)\n",
        "    end = time.time()\n",
        "    hours, rem = divmod(end-start, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
        "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPIxT4RB4_fC",
        "outputId": "4909515f-1869-45da-cf0e-8491493067b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss: 0.5973 train_acc: 0.7530 | val_loss: 0.5398 val_acc: 0.7836\n",
            "01:47:59.10\n",
            "Epoch 2: train_loss: 0.3623 train_acc: 0.8643 | val_loss: 0.5222 val_acc: 0.8072\n",
            "01:48:18.70\n",
            "Epoch 3: train_loss: 0.2096 train_acc: 0.9256 | val_loss: 0.6908 val_acc: 0.7939\n",
            "01:48:11.29\n",
            "Epoch 4: train_loss: 0.1295 train_acc: 0.9558 | val_loss: 0.7929 val_acc: 0.7891\n",
            "01:47:59.77\n",
            "Epoch 5: train_loss: 0.0916 train_acc: 0.9690 | val_loss: 0.8490 val_acc: 0.7906\n",
            "01:47:52.39\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, val_loader, optimizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Sentence Entailment BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "f96dea0ebdafa197f5aedddabb1bea429d3b0f4522770de9224a4846edf8913a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
